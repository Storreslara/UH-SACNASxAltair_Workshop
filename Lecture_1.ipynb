{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lecture 1: Getting to Know Your Data\n",
    "\n",
    "Author: Sebastian Torres-Lara\n",
    "\n",
    "## Overview\n",
    "\n",
    "Congrats, you have been hired as a data scientist at winery ! Your employer wants you to go over a dataset containing chemical information form over a thousand different wines.\n",
    "Your goal is to explore the dataset to understand the impact of each messaur"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tools of the Trade\n",
    "\n",
    "Data Science is constantly evolving whether it's new fancy machine learning algorithms, or an update to ChatGPT.\n",
    "My point is there are a lot of cool libraries, code editors, algorithm that\n",
    "As a data scientist you will have a wide array of tools at your disposal.\n",
    "\n",
    "For this lecture series we will be using Jupyter Notebooks to write and run our code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Getting your Data\n",
    "\n",
    "To start we need to get our hands on some data ! Luckily there are a ton of public data repos out there.\n",
    "\n",
    "For this case we will be using the\n",
    "\n",
    "*Side Note*:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the red wine quality data set (run the cell bellow) from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "- This dataset contains information about Vinho Verde, or green grape wine from Portugal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if your wine dataset has been downloaded, best to keep it in the same directory as this notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!ls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quick Tangent: Terminal Commands\n",
    "In case you're wondering, the ! allows you to input terminal commands in a Jupyter cell.\n",
    "While knowing terminal commands is not a must, they'll make you a more efficient coder\n",
    "1. `ls` (list) - displays a list of files and directories in the current directory.\n",
    "    * Example: `ls`\n",
    "\n",
    "2. `cd` (change directory) - changes the current working directory to the specified directory.\n",
    "    * Example: `cd /home/user/Documents`\n",
    "\n",
    "3. `mkdir` (make directory) - creates a new directory with the specified name.\n",
    "    * Example: `mkdir new_directory`\n",
    "\n",
    "4. `rm` (remove) - deletes a file or directory.\n",
    "    * Example: `rm file.txt` or `rm -r directory`\n",
    "\n",
    "5. `cp` (copy) - copies a file or directory to a new location.\n",
    "    * Example: `cp file.txt /home/user/Documents`\n",
    "\n",
    "6. `mv` (move) - moves a file or directory to a new location or renames it.\n",
    "    * Example: `mv file.txt new_location/file.txt` or `mv file.txt new_name.txt`\n",
    "\n",
    "7. `touch` - creates a new empty file with the specified name.\n",
    "    * Example: `touch new_file.txt`\n",
    "\n",
    "8. `cat` (concatenate) - displays the contents of a file.\n",
    "    * Example: `cat file.txt`\n",
    "\n",
    "9. `grep` (global regular expression print) - searches for a specific pattern in a file or files.\n",
    "    * Example: `grep \"hello\" file.txt`\n",
    "\n",
    "10. `sudo` (superuser do) - executes a command with administrative privileges.\n",
    "    * Example: `sudo apt-get update`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Understanding Your Data\n",
    "\n",
    "Now that we have our dataset we need to load it onto our notebook.\n",
    "To do this we will use the *pandas* library, a powerful data manipulation and analysis library\n",
    "- [Pandas user guide](https://pandas.pydata.org/docs/user_guide/index.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:38:59.871568Z",
     "end_time": "2023-04-03T09:38:59.890568Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data using `read_csv` and save it as `df`\n",
    "- Loads dataset onto the notebook as a [Dataframe](https://pandas.pydata.org/docs/reference/frame.html) object\n",
    "- For this dataset we have to use `delimiter` to specify the character or sequence of characters used to separate values in a  file when reading it into a pandas DataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', delimiter=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:39:02.600774Z",
     "end_time": "2023-04-03T09:39:02.634768Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the shape of your dataframe using: `df.shape`\n",
    "- output looks like this (row,column)\n",
    "- You'll often hear/read that the number of columns is referred as the number of features\n",
    "- Number of rows is also referred as the length of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `df.info()` to get some info...\n",
    "This functions will return the `Column name`, `Non-Null count` (count of real values), and `Dtype `"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "view the first 10 rows using: `df.head(10)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:47:56.311994Z",
     "end_time": "2023-04-03T10:47:56.389989Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "view the last 10 rows using `df.tail(10)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "view 10 random rows using `df.sample(10)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check the data types of each column (col) using: `df.dtypes`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if there are any NaN value (pandas data type for missing value) and count them using: `df.isna().sum()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Statistics\n",
    "\n",
    "Understanding the statics of your dataset is a must !!!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by using `df.describe()` to show  statistical information() of your dataframe.\n",
    "- count: Number of non-null observations for each column\n",
    "- mean: Arithmetic mean of each column (average)\n",
    "- std: Standard deviation of each column\n",
    "- min: Minimum value of each column\n",
    "- 25%: First quartile (25%) of each column\n",
    "- 50%: Median (50%) of each column\n",
    "- 75%: Third quartile (75%) of each column\n",
    "- max: Maximum value of each column\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "- Median: The median is a measure of central tendency that represents the middle value of a dataset. It is calculated by sorting the values in the dataset in ascending or descending order, and then selecting the value that is exactly in the middle. If the dataset has an odd number of values, the median is the middle value. If the dataset has an even number of values, the median is the average of the two middle values.\n",
    "\n",
    "- Standard Deviation: The standard deviation is a measure of the spread of a dataset. It measures how much the values in the dataset deviate from the mean. A low standard deviation indicates that the values are clustered around the mean, while a high standard deviation indicates that the values are more spread out. The standard deviation is calculated by taking the square root of the variance.\n",
    "\n",
    "- Quartiles: The quartiles are values that divide a dataset into quarters. The 25th quartile (Q1) is the value that is greater than or equal to 25% of the values in the dataset. The 50th quartile (Q2) is the same as the median. The 75th quartile (Q3) is the value that is greater than or equal to 75% of the values in the dataset. The interquartile range (IQR) is the difference between the 75th and 25th quartiles, and it represents the middle 50% of the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If using `descrtibe()` seems overwhelming you can get key stats (using their unique attribute call) for the entire dataframe or col(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting maxium values for each col in the dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a single col, for this case we want the max of `Ph`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['pH'].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a multiple cols, for this case we want the max of `Ph and chlorides`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[['pH', 'chlorides']].max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a list of other useful stats call. Same col selection or whole df applies.\n",
    "- `min()`\n",
    "- `mean()`\n",
    "- `mode()`\n",
    "    - returns the most frequent value of the df/col\n",
    "- `median()`\n",
    "- `quantile(q)`\n",
    "    - 0 <=q <= 1  (25th == 0.25)\n",
    "- `std()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlation (Pearson Correlation)\n",
    "Correlation measures the strength and direction of the *linear relationship* between two continuous variables.\n",
    "It is denoted by the symbol \"r\" and ranges between -1 and 1, where -1 indicates a perfect negative linear correlation, 0 indicates no correlation, and 1 indicates a perfect positive linear correlation.\n",
    "\n",
    "You can get the correlation of your df using: `df.corr()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.corr()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Visualization Using Plotly\n",
    "\n",
    "Let's be honest seeing a bunch of numbers on your screen can be confusing, especially when you are trying understand their behavior.\n",
    "This where data visualization comes into play.\n",
    "There are a bunch of awesome visualization tools out there such as: Matplotlib, Seaborn, Holoviews, Plotly, and many more\n",
    "For this section we will be using Plotly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import plotly's express library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from plotly import express as px"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:38:58.761799Z",
     "end_time": "2023-04-03T09:38:59.012798Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bar graphs are great for showing how occurrences are per unique value of a feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.bar(df['quality'].value_counts(), title=r'$\\text{You can also flex on people by using LaTex, here a bunch of math stuff: } \\int \\sigma (x)^{420}dx$').update_xaxes(title='Rating').update_yaxes(title='Count')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:39:13.382939Z",
     "end_time": "2023-04-03T09:39:13.709862Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our data (chemical measurements) is composed of continuous distributions. To visualize this kind of data is best to use a [histogram](https://datavizcatalogue.com/methods/histogram.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(df,'pH')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.histogram(df,'citric acid')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are all sort of data visualization methods, and sometimes it's trivial which kind of plot to use.\n",
    "However, [The Data Visualisation Catalogue](https://datavizcatalogue.com/index.html) is great guide on how use different types of visualizations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can visualize the correlation using"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.imshow(df.corr())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:40:07.340133Z",
     "end_time": "2023-04-03T09:40:07.394131Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables.\n",
    "In its simplest form, linear regression assumes a linear relationship between the variables.\n",
    "The goal of linear regression is to find the line that best fits the data, so that we can use it to predict values of the dependent variable for new values of the independent variable(s).\n",
    "\n",
    "For this section we will be utilizing the Sci-Kit Learn library  a popular open-source machine learning library for Python that provides tools for various supervised and unsupervised learning algorithms, as well as data preprocessing and model evaluation techniques.\n",
    "It is designed to be easy to use, efficient, and accessible to both novice and expert machine learning practitioners.\n",
    "\n",
    "Here is the doc page for [Sci-Kit Learn Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we import the necessary libraries: Pandas for data handling, NumPy for numerical operations, scikit-learn for machine learning, and StandardScaler for data scaling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:45:47.121848Z",
     "end_time": "2023-04-03T09:45:47.157413Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select the features (X) and the target variable (y).\n",
    "We drop the 'quality' column from X, as we will use it to predict the target variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use StandardScaler to scale the data. Scaling the data can help improve the accuracy of the model, as it ensures that each feature has a similar range of values.\n",
    "\n",
    "The StandardScaler scales data by subtracting the mean from each data point and dividing the result by the standard deviation.\n",
    "This transformation results in data with a mean of zero and a standard deviation of one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data into training and testing sets, using train_test_split.\n",
    "This function randomly splits the data into two sets based on the test_size parameter (in this case, 20%).\n",
    "We set the random_state parameter to ensure that we get the same split each time we run the code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit the linear regression model to the training data using the fit() method of the LinearRegression object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the model to make predictions on the test data using the predict() method of the LinearRegression object."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate the R-squared score of the model using the score() method of the LinearRegression object.\n",
    "The R-squared score is a measure of how well the model fits the data, with a score of 1 indicating a perfect fit.\n",
    "\n",
    "R-squared is the  measure of the goodness of fit of a regression model.\n",
    "It helps to determine how well the model fits the data and whether the independent variables are able to explain a significant portion of the variation in the dependent variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = regressor.score(X_test, y_test)\n",
    "\n",
    "print('R-squared score:', score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decision trees are a type of supervised learning algorithm used for classification and regression.\n",
    "In classification, a decision tree learns a mapping from input features to discrete output classes.\n",
    "The tree is built by recursively splitting the data into subsets based on the values of the input features, with the goal of maximizing the separation between the output classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T09:45:33.664300Z",
     "end_time": "2023-04-03T09:45:34.069255Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make a new X and y, this time let's call them X_tree and y_tree.\n",
    "Scale X_tree using the `StandardScaler`\n",
    "Then split your data into training and testing sets using sk's `train_test_split()`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_tree = df.drop('quality',axis=1)\n",
    "y_tree = df['quality']\n",
    "scaler = StandardScaler()\n",
    "X_tree = scaler.fit_transform(X_tree)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tree, y_tree, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:49:46.197350Z",
     "end_time": "2023-04-03T10:49:46.222346Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the `DecisionTreeClassifier` as `clf` and then fit it with your training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:49:47.743518Z",
     "end_time": "2023-04-03T10:49:47.769518Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After fitting make a prediction and call it `y_tree_pred`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_tree_pred = clf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T10:49:49.810024Z",
     "end_time": "2023-04-03T10:49:49.834026Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the accuracy of your classifier by using `accuracy_score(y_test, y_tree_pred)`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_tree_pred)\n",
    "print(f'Accuracy: {acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T11:58:10.702524Z",
     "end_time": "2023-04-03T11:58:10.729523Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The confusion matrix is a table used to evaluate the performance of a classification model by comparing the predicted and actual labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T11:24:26.710969Z",
     "end_time": "2023-04-03T11:24:26.730967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=y_tree_pred)\n",
    "print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T11:37:50.744697Z",
     "end_time": "2023-04-03T11:37:50.762695Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make our confusion matrix more readable lets turn it into a dataframe and add labels\n",
    "\n",
    "To get our labels, we'll use `df['quality'].unique()` to get a list of all the unique values and use numpy's `sort()` to sort all the values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cm_label = np.sort(df['quality'].unique(), axis=0)\n",
    "cm_df = pd.DataFrame(cm, columns=cm_label, index=cm_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T11:52:48.156315Z",
     "end_time": "2023-04-03T11:52:48.182314Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T11:52:50.280225Z",
     "end_time": "2023-04-03T11:52:50.329224Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
